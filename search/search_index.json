{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to DocForensics","text":"<p>DocForensics is a cutting-edge solution designed to localize and identify various forms of document tampering and malicious alterations. Our solution aids in unveiling copy-move, splicing, erasing, and text redaction attacks, providing a reliable foundation for digital document verification and integrity assurance.</p> <p></p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Copy-Move Detection: Identify and localize instances of copy-move forgery within digital documents.</li> <li>Splicing Detection: Detect splicing attacks aimed at merging content from different sources.</li> <li>Erasing Detection: Uncover erasing attempts to remove original content from documents.</li> <li>Masking Detection: Identify areas within an image or document where a solid or patterned overlay has been applied to conceal underlying content, such as in text redaction or image obscuration.</li> <li>Inpainting Detection: Identify and localize instances where missing or altered areas within a document have been filled in with generated content to create a seamless appearance.</li> </ul>"},{"location":"#why-choose-document-forensic-solution","title":"Why Choose Document Forensic Solution?","text":"<ul> <li>Accuracy: Employing advanced machine learning algorithms, DocForensics provides a high degree of accuracy in detecting various document forgery types.</li> <li>Speed: Process documents swiftly to ensure timely forensic analysis.</li> <li>User-Friendly Interface: Easy-to-use UI ensures a smooth user experience, even for individuals with minimal technical expertise.</li> <li>Comprehensive Reports: Generate detailed forensic reports to support legal and compliance requirements.</li> <li>Continuous Improvement: Regular updates and enhancements to keep pace with evolving forgery techniques.</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<p>Ready to explore the Document Forensic Solution? Head over to the Getting Started section for installation instructions and initial configuration guidelines.</p>"},{"location":"api_documentation/","title":"API Documentation","text":""},{"location":"api_documentation/#api-documentation","title":"API Documentation","text":""},{"location":"api_documentation/#base-url","title":"Base URL:","text":"<p>http://0.0.0.0:6003/docs</p>"},{"location":"api_documentation/#endpoint-post-apipredict","title":"Endpoint: POST <code>/api/predict</code>","text":""},{"location":"api_documentation/#description","title":"Description:","text":"<p>This endpoint handles file uploads as well as Base64 code processing to perform forensic checking on the provided image data.</p>"},{"location":"api_documentation/#parameters","title":"Parameters:","text":"<ul> <li><code>file_data</code> (type: <code>UploadedFile</code>, optional): The uploaded file object. Defaults to None.</li> <li><code>base64_data</code> (type: <code>Base64Code</code>, optional): The Base64 code object. Defaults to None.</li> <li><code>file_name</code> (type: <code>string</code>, optional): An optional filename for the uploaded image. </li> <li><code>transaction_id</code> (type: <code>string</code>, required): A unique identifier for the transaction.</li> </ul>"},{"location":"api_documentation/#request-body","title":"Request Body:","text":"<ul> <li><code>multipart/form-data</code><ul> <li><code>image_file</code>: <code>string($binary)</code> - The image file. Optional. Default None.</li> <li><code>base64_data</code>: <code>string</code> - Base64 data of the image. Default None.</li> <li><code>file_name</code>: <code>string</code> - Optional filename for the image.</li> <li><code>transaction_id</code>: <code>string</code> - A unique identifier for the transaction. Required.</li> </ul> </li> </ul>"},{"location":"api_documentation/#responses","title":"Responses:","text":"<ul> <li> <p><code>200 OK</code>: Successful Response</p> <ul> <li>Media Type: <code>application/json</code></li> <li>Example Value:     <pre><code>{\n  \"label\": \"tampered\",\n  \"data_stats\": {\n    \"mask_percentage\": 0.8594512939453125,\n    \"img_width\": 512,\n    \"img_height\": 512,\n    \"total_pixels\": 262144,\n    \"total_non_zero_pixels\": 2253\n  },\n  \"transaction_id\": \"1234\",\n  \"out_mask\": \"base-64-data\",\n  \"out_color_mask\": \"base-64-data\",\n  \"doc_integrity_verification_result\": {\n    \"is_logo_detected\": true,\n    \"is_flag_detected\": true,\n    \"is_hologram_detected\": true,\n    \"is_crop_detected\": false,\n    \"is_barcode_detected\": false,\n    \"logo_detection_confidence\": 0.9630905389785767,\n    \"flag_detection_confidence\": 0.9408931136131287,\n    \"hologram_detection_confidence\": 0.9314528107643127,\n    \"spiral_detection_confidence\": 0.6021785736083984,\n    \"is_spiral_lines_detected\": false\n  }\n}\n</code></pre></li> </ul> </li> <li> <p><code>422 Unprocessable Entity</code>: Validation Error</p> <ul> <li>Media Type: <code>application/json</code></li> <li>Example Value:     <pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                \"string\",\n                0\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre></li> </ul> </li> </ul>"},{"location":"api_documentation/#usage","title":"Usage:","text":"<p>To use this endpoint, you can either upload an image file directly or provide the image data as Base64 code. Additionally, you can optionally provide a filename and a required transaction ID for tracking purposes. Upon successful processing, the endpoint will return a JSON response containing the forensic analysis results.</p>"},{"location":"challenges/","title":"Challenges","text":"<p>Document image forensics is a challenging field due to the nuances of document manipulations and the advancement of forgery techniques. Some of the primary challenges faced in this area include:</p> <ol> <li> <p>Sophisticated Editing Tools: Modern software provides advanced tools that make manipulations seamless, making detection difficult.</p> </li> <li> <p>Variability of Documents: Different documents have varying layouts, styles, fonts, and formats, which adds to the complexity of forgery detection.</p> </li> <li> <p>High-Quality Reproductions: With advancements in printing and scanning technologies, forgers can produce high-quality replicas of original documents.</p> </li> <li> <p>Loss of Image Quality: Multiple generations of copying, rescanning, and compressing can degrade the image, obscuring traces of manipulation.</p> </li> <li> <p>Source Camera Identification: For digital photos of documents, identifying the source camera can be challenging, especially if metadata is tampered with.</p> </li> <li> <p>Machine Learning and AI: Advanced algorithms can now generate synthetic images or tamper with existing ones in a way that's hard for traditional methods to detect.</p> </li> <li> <p>Digital vs. Physical Tampering: Differentiating between tampering done on a physical document before scanning versus manipulation of the digital image after scanning can be difficult.</p> </li> <li> <p>Consistency Checking: Determining the consistency of light, shadows, and perspectives requires a detailed understanding of the document's original environment.</p> </li> <li> <p>Scale and Complexity: Automated solutions must process a vast number of documents rapidly, yet many forensic techniques can be computationally intensive.</p> </li> <li> <p>Lack of Ground Truth: For training detection models or validating methods, there is often a lack of a comprehensive dataset of forged documents with ground truth annotations.</p> </li> <li> <p>Global Variability: Official documents, like passports or IDs, vary significantly from one country or institution to another, making standardized verification challenging.</p> </li> <li> <p>Evolution of Forgery Techniques: As forensic methods improve, so do forgery techniques, leading to an ongoing cat-and-mouse game.</p> </li> <li> <p>Lack of Standardization: There isn't always a standardized procedure or benchmark for different forensic tasks, leading to variations in performance evaluations.</p> </li> <li> <p>Ethical and Privacy Concerns: In the age of data privacy, accessing or storing certain document details for forensic purposes can raise ethical and legal concerns.</p> </li> <li> <p>Loss of Integrity:</p> <ul> <li>Natural Aging: Caused by the natural aging of the document over time.</li> <li>Fading of Ink: Due to exposure to light, age, or chemical interactions.</li> <li>Degradation of Paper: Resulting from environmental conditions or poor-quality materials.</li> <li>Detection Difficulty: Reduced clarity and faded features in worn-out documents.</li> <li>Digital Restoration Artifacts: Digital enhancement efforts can unintentionally introduce or hide important details.</li> <li>Advanced Imaging Challenges: The need for specialized imaging methods to discern faded or hidden details.</li> <li>Variable Degradation: Different sections of the document may degrade at varied rates, affecting uniformity.</li> <li>Background Interference: Grain, patterns, or imperfections in paper can overshadow key content.</li> <li>Chemical Alterations: Age or environmental factors can change the chemical properties of ink or paper.</li> <li>Environmental Damage: Including water/moisture damage causing smudging and ink bleed, and burn/heat damage leading to charing or warping.</li> <li>Fragmentation Issues: Missing pieces or fragments from torn documents.</li> <li>False Positives: Natural wear and tear, or other benign changes, can sometimes resemble tampering or alterations.</li> </ul> </li> <li> <p>Document Image Quality:</p> <ul> <li>Resolution: The clarity of the document, determining how well details can be seen. Low resolution might omit important details.  </li> <li>Noise: Random variations in brightness or color information. High noise levels can mask fine details and introduce unwanted artifacts.</li> <li>Compression Artifacts: Unwanted patterns or detail degradation resulting from image compression, especially noticeable with aggressive lossy compression.</li> <li>Sharpness: The clarity of edges and details. Blurred images might hide alterations or make genuine details appear altered.</li> <li>Brightness and Contrast Variations: Uneven or incorrect brightness and contrast levels can lead to distorted colors or exaggerated details.</li> <li>Moire Patterns: Unwanted patterns that arise when scanning printed materials, interfering with the original content of the document.</li> <li>Distortions: Any warping, stretching, or perspective changes that alter the original appearance of the document.</li> <li>Background Noise: Extraneous information or artifacts that can obscure the genuine content of the document.</li> <li>Non-uniform Illumination: Shadows, highlights, or uneven lighting conditions that can distort the appearance of a document.</li> <li>Scanner/Camera Quality: The fidelity with which a capture device reproduces the document. Low-quality devices may not capture details accurately.</li> <li>Environmental Factors: Issues like glare, reflections, and other environmental elements that can impact the quality during document capture.</li> </ul> </li> </ol> <p>To overcome these challenges, ongoing research, collaboration, and continuous tool development are crucial. The integration of machine learning and traditional forensic techniques is also an exciting avenue, leading to improved detection rates and faster processing.</p>"},{"location":"dataset_composition/","title":"Dataset Composition","text":""},{"location":"dataset_composition/#dataset-composition","title":"Dataset Composition","text":"<p>To train our model to recognize manipulations, we provide it with several hundred thousand images, both genuine and manipulated. Each image is paired with its ground truth mask. During the training process, the model learns to recognize patterns and subtle hints that suggest an image has been tampered with.</p>"},{"location":"dataset_composition/#genuine-images","title":"Genuine Images","text":"<p>These are untouched, original images. The ground truth mask for these images is purely black, indicating no regions of manipulation.</p>"},{"location":"dataset_composition/#manipulated-images","title":"Manipulated Images","text":"<p>These images have undergone some form of tampering. Accompanying each manipulated image is its ground truth mask, where:</p> <ul> <li>White regions: Highlight areas of the image that have been altered or tampered with.</li> <li>Black regions: Signify areas of the image that remain untouched or genuine.</li> </ul>"},{"location":"features/","title":"Forensic Features","text":"<p>The Document Forensic Project is equipped with several forensic features designed to detect and analyze digital manipulations within documents. Each feature focuses on a particular type of forgery, providing a detailed analysis to help verify the authenticity of digital documents.</p> <ul> <li>Forensic Features<ul> <li>Splicing Detection</li> <li>Copy-Move Detection</li> <li>Erasing Detection</li> <li>Masking Detection</li> <li>Inpainting Detection</li> </ul> </li> </ul>"},{"location":"features/#splicing-detection","title":"Splicing Detection","text":"<p>Image splicing (or Compositing) involves cutting a portion of one image and pasting it onto another. In the context of document forgery, it's taking a part of one official document and merging it with another to create a deceptive document.</p> <ul> <li>Example 1: Combining the photo from a stolen passport with the details page of a different, valid passport.</li> <li> <p>Example 2: Merging the signature from one driving license onto another to make the latter appear genuine.</p> </li> <li> <p>Example 3: Combining Two Passports:</p> <ul> <li>Scenario: A person has an expired passport with a valid visa and a new passport without that visa. They want to use the valid visa from the expired passport while traveling with their new passport.</li> <li>Splicing Action: The forger cuts out the visa page or stamp from the expired passport and pastes it onto a page in the new passport. It's made to look seamless, as if the visa was genuinely issued in the newer passport.</li> <li>Real-world Consequence: This allows the person to travel based on a visa that isn't actually linked to their current passport. If undetected, they can utilize an expired visa as if it were still valid.</li> </ul> </li> <li> <p>Example 4: Merging Different Driving Licenses:</p> <ul> <li>Scenario: Someone has a driving license with a bad driving record (e.g., DUIs or major traffic offenses) and acquires another license under a different identity with a clean record. However, they prefer the photo from the original license.</li> <li>Splicing Action: The forger takes the photo from the original license (with the bad record) and splices it onto the new license (with the clean record).</li> <li>Real-world Consequence: The individual can present a license with a clean driving record but with their preferred photo, potentially evading legal consequences or higher insurance rates linked to their actual driving history.</li> </ul> </li> <li> <p>Example 5: Manipulating National ID Expiry Dates:</p> <ul> <li>Scenario: Someone's national ID card is about to expire, which could limit certain privileges like voting.</li> <li>Splicing Action: The forger finds someone else's national ID card that has a more distant expiry date, cuts out just the date, and splices it over the expiry date on the original ID.</li> <li>Real-world Consequence: This alteration might allow someone to use an expired ID as if it's still valid, potentially engaging in civic duties or accessing services under false pretenses.</li> </ul> </li> </ul> <p> </p> Example: The individual's actual face has been substituted with a different face."},{"location":"features/#copy-move-detection","title":"Copy-Move Detection","text":"<p>Copy-move forgery is a type of manipulation where a part/segment of the document (or image) is copied and pasted into another location within the same document, often to replicate or hide specific elements. Think of it as a digital \"cut and paste\" within the same image.</p> <ul> <li>Example 1: In a passport, copying the holographic emblem and placing it onto a forged version to enhance its perceived authenticity.</li> <li> <p>Example 2: Duplicating a legitimate visa stamp on a page of a passport where an expired or rejected visa was previously.</p> </li> <li> <p>Example 3: Passport Number Manipulation:</p> <ul> <li>Scenario: A forger wants to change their passport number to avoid detection or link to past records.</li> <li>Copy-Move Action: The forger copies some digits from the birth date or expiry date sections of their passport and pastes them onto the passport number, thereby altering it.</li> <li>Real-world Consequence: If undetected, the individual might bypass certain checks at immigration or during other verification processes.</li> </ul> </li> <li> <p>Example 4: Driver's License Issue Date Alteration:</p> <ul> <li>Scenario: A young driver wants to appear as if they've had their driver's license for a longer period than they actually have, possibly to reduce insurance premiums or qualify for jobs requiring longer driving experience.</li> <li>Copy-Move Action: The forger carefully copies digits from the birthdate section or other parts of the driver's license and pastes them over the issue date, making it seem as though the license was issued earlier than it actually was.</li> <li>Real-world Consequence: The person could unlawfully get benefits or positions that require more extended driving experience or a specific age.</li> </ul> </li> </ul> <p> </p> Example: The individual's face has been copied and pasted to a different location within the same document."},{"location":"features/#erasing-detection","title":"Erasing Detection","text":"<p>This involves removing certain elements from an image. In the context of digital image editing, erasing would mean removing specific pixels representing an object or detail to either leave a blank space or replace them with a uniform background.</p> <ul> <li>Example 1: Removing an expiry date from a driving license and using the background pattern to fill in the space seamlessly.</li> <li>Example 2: Erasing a restriction or endorsement from a driving license and cloning adjacent background areas to cover the alteration.</li> </ul> <p> </p> Example: The ID number and signature have been erased from the document."},{"location":"features/#masking-detection","title":"Masking Detection","text":"<p>Covering up parts of an image or document with a solid or patterned overlay to hide underlying content.</p> <ul> <li>Example 1: To hide a person's Social Security Number (SSN) on a copied version of a national ID, a black box is placed over the number.</li> <li>Example 2: In a publicly released document, portions of the text are covered with redaction bars to prevent specific details from being disclosed.</li> </ul> <p> </p> Example: Text redaction has been applied to the image to conceal significant details."},{"location":"features/#inpainting-detection","title":"Inpainting Detection","text":"<p>Inpainting is a technique used to fill in missing or removed parts of an image in a way that is visually coherent with the rest of the image. It's more advanced than simple erasing because the goal of inpainting is to make the edited region look natural, as if the object was never there.</p> <ul> <li>Example: If someone were to erase a stamp (leaving a blank area), inpainting would involve filling that blank area with content (like background texture and color) that matches the surrounding region of the passport, making it appear as if the stamp was never there.</li> </ul> <p> </p> Example: Details have been erased and subsequently filled with background texture and color utilizing AI, making the alterations appear seamless and undetectable.    <p>Each forensic feature is meticulously engineered to provide accurate and insightful analysis, aiding in the identification and understanding of digital manipulations within documents. The combination of these features allows for a comprehensive examination of digital documents to ensure their authenticity and integrity.</p> <p>For further details or inquiries regarding the forensic features, feel free to contact our support team.</p>"},{"location":"getting_started/","title":"Getting Started with Document Forensics Project","text":"<p>This page will guide you through the initial setup and installation process to get the Document Forensics Project up and running on your machine.</p>"},{"location":"getting_started/#prerequisites","title":"Prerequisites:","text":"<p>Before proceeding with the installation, ensure you have the following prerequisites met on your machine:</p> <ul> <li> <p>Operating System: </p> <ul> <li>Linux (Ubuntu 18.04 LTS or later is recommended)</li> <li>macOS (10.14 Mojave or later)</li> <li>Windows 10 Pro, Enterprise or Education (64-bit, Build 15063 or later)</li> </ul> </li> <li> <p>Hardware:</p> <ul> <li>CPU: At least 4 cores</li> <li>RAM: 12 GB or more</li> <li>Disk Space: 50 GB or more of free space</li> <li>GPU: A modern nvidia GPU with memory &gt; 12 GB is recommended to provide a significant speedup in predictions.</li> </ul> </li> <li> <p>Software:</p> <ul> <li>Docker: Follow the official Docker installation guide to install Docker on your machine.</li> <li>Docker Compose: Follow the official Docker Compose installation guide to install Docker Compose on your machine.</li> <li>GPU driver: If you are setting up project on nvidia gpu, then driver version &gt;= 525 will be required.</li> </ul> </li> <li> <p>Others:</p> <ul> <li>Stable internet connection for cloning the repository and downloading dependencies.</li> <li>Access to a terminal or command prompt.</li> </ul> </li> </ul> <p>Ensure that your machine meets the above specifications to ensure smooth operation of the Document Forensics Project.</p>"},{"location":"getting_started/#installation-guide","title":"Installation Guide:","text":"<p>This guide provides detailed instructions on how to set up the Document Forensics Project on your machine. You can choose to set up the project on a CPU or a GPU, though a GPU setup is recommended due to its advantages in speeding up predictions.</p> <ol> <li>Clone the Repository:    Clone the project repository to your local machine using the following command:</li> </ol> <pre><code>git clone https://github.com/Nivratti/DocForensics_Mauritius_Inference.git\ncd DocForensics_Mauritius_Inference\n</code></pre>"},{"location":"getting_started/#gpu-setup-recommended","title":"GPU Setup (Recommended):","text":"<p>There are three distinct methods available for setting up the project on a GPU: Docker, Docker Compose, and using the <code>setup.sh</code> script. You can opt for any of these methods depending on your preferences or the specifics of your environment setup.</p> <ul> <li>i) Docker Setup:</li> <li>ii) Docker Compose Setup</li> <li>iii) Script Setup</li> </ul>"},{"location":"getting_started/#docker-setup","title":"Docker Setup:","text":"<p>This guide provides instructions on setting up the Document Forensics Project on a GPU using Docker.</p> <ol> <li> <p>Build the Docker Image:</p> <p>In the project directory, you'll find a file named <code>Dockerfile</code>. This file contains the instructions to build the Docker image for the GPU setup. Build the Docker image using the following command:</p> <pre><code>docker build -t docforensics_mauritius_inference:latest .\n</code></pre> </li> <li> <p>Run the Docker Container:       Now, run the Docker container from the image you just built. This will start the Document Forensics Project on your machine:</p> <pre><code>docker run --name docforensics_mauritius_inference -p 6003:6003 docforensics_mauritius_inference:latest\n</code></pre> </li> <li> <p>Accessing the Project:       Once the Docker container is up and running, you can access the Document Forensics Project through your web browser using the URL: <code>http://localhost:6003</code></p> </li> <li> <p>Stopping the Project:       To stop the Document Forensics Project and the running container, use the following command:       <pre><code>docker stop docforensics_mauritius_inference\n</code></pre></p> </li> </ol>"},{"location":"getting_started/#docker-compose-setup","title":"Docker Compose Setup","text":"<p>Docker Compose facilitates the management of multi-container Docker applications, making it a convenient method for setting up the Document Forensics Project on a GPU. Here's how to proceed:</p> <ol> <li> <p>Prepare the Docker Compose File:    Ensure you have a <code>docker-compose.yml</code> file in the project directory. The file should have the content as provided above, tailored to the specifics of the Document Forensics Project and GPU setup.</p> </li> <li> <p>Build the Docker Images:    Navigate to the project directory where the <code>docker-compose.yml</code> file is located, and execute the following command to build the Docker images:    <pre><code>sudo docker-compose build\n</code></pre></p> </li> <li> <p>Start the Docker Containers:    Now, start the Docker containers using the following command:    <pre><code>sudo docker-compose up\n</code></pre></p> </li> <li> <p>Accessing the Project:    Once the Docker containers are up and running, access the Document Forensics Project through your web browser using the URL: <code>http://localhost:6003</code></p> </li> <li> <p>Stopping the Project:    To stop the Document Forensics Project and the running containers, use the following command:    <pre><code>sudo docker-compose down\n</code></pre></p> </li> </ol> <p>These steps outline the procedure for setting up and managing the Document Forensics Project on a GPU using Docker Compose.</p>"},{"location":"getting_started/#script-setup","title":"Script Setup","text":"<p>The <code>setup.sh</code> script is a straightforward method to set up the Document Forensics Project on a GPU. This script will create a new Conda environment and install all the necessary dependencies. Ensure you have Anaconda installed on your system before proceeding.</p> <ol> <li> <p>Run the Setup Script:    Make the script executable and run it to set up the project:    <pre><code>chmod +x setup.sh\n./setup.sh\n</code></pre></p> </li> <li> <p>Activate the Conda Environment:    Once the script execution completes, activate the new Conda environment created by the script:    <pre><code>conda activate document-forensics-gpu\n</code></pre></p> </li> <li> <p>Start the Project:    Now, with the Conda environment activated, start the Document Forensics Project:    <pre><code>python main.py\n</code></pre></p> </li> <li> <p>Accessing the Project:    Once the project is up and running, access it through your web browser using the URL: <code>http://localhost:6003</code></p> </li> <li> <p>Stopping the Project:    To stop the Document Forensics Project, simply terminate the running process in the terminal using <code>Ctrl + C</code>.</p> </li> <li> <p>Deactivate the Conda Environment:    After stopping the project, deactivate the Conda environment:    <pre><code>conda deactivate\n</code></pre></p> </li> </ol> <p>These steps outline the process to set up the Document Forensics Project on a GPU using the <code>setup.sh</code> script. This method requires Anaconda to be installed on the system, as it relies on Conda environments to manage dependencies. ```</p> <p>In this section, a step-by-step procedure is provided to set up the Document Forensics Project on a GPU using the <code>setup.sh</code> script. It includes making the script executable, running it, activating the newly created Conda environment, starting the project, and how to access, stop, and deactivate the environment post usage.</p>"},{"location":"getting_started/#cpu-setup","title":"CPU Setup:","text":"<p>There are three distinct methods available for setting up the project on a CPU: Docker, Docker Compose, and using the <code>setup_cpu.sh</code> script. You can opt for any of these methods depending on your preferences or the specifics of your environment setup.</p> <ul> <li>i) Docker Setup On CPU:</li> <li>ii) Docker Compose Setup On CPU</li> <li>iii) Script Setup On CPU</li> </ul>"},{"location":"getting_started/#docker-setup-on-cpu","title":"Docker Setup On CPU:","text":"<p>This guide provides instructions on setting up the Document Forensics Project on a CPU using Docker.</p> <ol> <li> <p>Build the Docker Image:</p> <p>In the project directory, you'll find a file named <code>Dockerfile-cpu</code>. This file contains the instructions to build the Docker image for the CPU setup. Build the Docker image using the following command:</p> <p><code>bash sudo docker build -f \"Dockerfile-cpu\" -t docforensics_mauritius_inference_cpu:latest .</code></p> </li> <li> <p>Run the Docker Container:     Now, run the Docker container from the image you just built. This will start the Document Forensics Project on your machine:</p> <p><code>bash sudo docker run --name docforensics_mauritius_inference_cpu -p 6003:6003 docforensics_mauritius_inference_cpu:latest</code></p> </li> <li> <p>Accessing the Project:     Once the Docker container is up and running, you can access the Document Forensics Project through your web browser using the URL: <code>http://localhost:6003</code></p> </li> <li> <p>Stopping the Project:     To stop the Document Forensics Project and the running container, use the following command:</p> <p><code>bash sudo docker stop docforensics_mauritius_inference_cpu</code></p> </li> </ol>"},{"location":"getting_started/#docker-compose-setup-on-cpu","title":"Docker Compose Setup On CPU","text":"<p>Docker Compose facilitates the management of multi-container Docker applications, making it a convenient method for setting up the Document Forensics Project on a CPU. Here's how to proceed:</p> <ol> <li> <p>Prepare the Docker Compose File:     Ensure you have a <code>docker-compose-cpu.yml</code> file in the project directory. The file should have the content as provided above, tailored to the specifics of the Document Forensics Project and CPU setup.</p> </li> <li> <p>Build the Docker Images:     Navigate to the project directory where the <code>docker-compose-cpu.yml</code> file is located, and execute the following command to build the Docker images:</p> <p><code>bash sudo docker compose -f \"docker-compose-cpu.yml\" build</code></p> </li> <li> <p>Start the Docker Containers:     Now, start the Docker containers using the following command:</p> <p><code>bash sudo docker compose -f \"docker-compose-cpu.yml\" up</code></p> </li> <li> <p>Accessing the Project:     Once the Docker containers are up and running, access the Document Forensics Project through your web browser using the URL: <code>http://localhost:6003</code></p> </li> <li> <p>Stopping the Project:     To stop the Document Forensics Project and the running containers, use the following command:</p> <p><code>bash sudo docker compose -f \"docker-compose-cpu.yml\" down</code></p> </li> </ol>"},{"location":"getting_started/#script-setup-on-cpu","title":"Script Setup On CPU","text":"<p>The <code>setup_cpu.sh</code> script is a straightforward method to set up the Document Forensics Project on a CPU. This script will create a new Conda environment and install all the necessary dependencies. Ensure you have Anaconda installed on your system before proceeding.</p> <ol> <li> <p>Run the Setup Script:     Make the script executable and run it to set up the project:</p> <p><code>bash chmod +x setup_cpu.sh ./setup_cpu.sh</code></p> </li> <li> <p>Activate the Conda Environment:     Once the script execution completes, activate the new Conda environment created by the script:</p> <p><code>bash conda activate document-forensics-cpu</code></p> </li> <li> <p>Start the Project:     Now, with the Conda environment activated, start the Document Forensics Project:</p> <p><code>bash python main.py</code></p> </li> <li> <p>Accessing the Project:     Once the project is up and running, access it through your web browser using the URL: <code>http://localhost:6003</code></p> </li> <li> <p>Stopping the Project:     To stop the Document Forensics Project, simply terminate the running process in the terminal using <code>Ctrl + C</code>.</p> </li> <li> <p>Deactivate the Conda Environment:     After stopping the project, deactivate the Conda environment:</p> <p><code>bash conda deactivate</code></p> </li> </ol> <p>These steps outline the process to set up the Document Forensics Project on a CPU using the <code>setup_cpu.sh</code> script. This method requires Anaconda to be installed on the system, as it relies on Conda environments to manage dependencies.</p>"},{"location":"getting_started/#initial-configuration","title":"Initial Configuration:","text":"<p>No initial configuration is required to get started with the Document Forensics Project. Once the installation steps are completed, you can begin using the system to analyze digital documents for forensic purposes.</p> <p>Feel free to explore the project documentation further to understand the various features and functionalities available within the Document Forensics Project.</p>"},{"location":"input_image_requirements/","title":"Document Forensic - Input Image Requirements","text":"<p>For accurate analysis and meaningful results, it's important to adhere to certain image specifications when using the Document Forensic Project. Below are the image requirements:</p>"},{"location":"input_image_requirements/#1-supported-formats","title":"1. Supported Formats:","text":"<ul> <li>PNG</li> <li>JPG</li> <li>JPEG</li> <li>WEBP</li> </ul>"},{"location":"input_image_requirements/#2-resolution-requirements","title":"2. Resolution Requirements:","text":"<ul> <li>Minimum Resolution: No specific limit</li> <li>Maximum Resolution: No specific limit</li> <li>Recommended Resolution: Full HD (1920 x 1080 pixels)</li> </ul>"},{"location":"input_image_requirements/#3-color-modes","title":"3. Color Modes:","text":"<ul> <li>RGB</li> </ul>"},{"location":"input_image_requirements/#4-aspect-ratio","title":"4. Aspect Ratio:","text":"<ul> <li>Any aspect ratio is acceptable.</li> </ul>"},{"location":"input_image_requirements/#5-maximum-file-size","title":"5. Maximum File Size:","text":"<ul> <li>There is no specific limit on the file size. However, very large files will take more time to upload.</li> </ul>"},{"location":"input_image_requirements/#6-image-quality","title":"6. Image Quality:","text":"<ul> <li>High-quality images yield the best results.</li> <li>Images containing glare, being overly bright or dark, having low clarity, excessive noise, or many artifacts may result in false positives or inaccurate analysis.</li> </ul> <p>For optimal results, it's advised to use high-quality, clear images with a resolution of Full HD. Adhering to these specifications will ensure a higher degree of accuracy and reliability in the analysis provided by the Document Forensic Project.</p>"},{"location":"performance_metrices/","title":"Performance metrices","text":""},{"location":"performance_metrices/#performance-metrics-for-document-forensics","title":"Performance Metrics for Document Forensics","text":"<ol> <li> <p>Accuracy:</p> <ul> <li>Measures the proportion of correctly identified instances among all instances.</li> <li>Formula: ( \\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}} )</li> </ul> </li> <li> <p>Precision:</p> <ul> <li>Evaluates the proportion of true positive predictions among all positive predictions.</li> <li>Formula: ( \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} )</li> </ul> </li> <li> <p>Recall (Sensitivity):</p> <ul> <li>Assesses the proportion of true positive predictions among all actual positives.</li> <li>Formula: ( \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} )</li> </ul> </li> <li> <p>F1-Score:</p> <ul> <li>Provides a balance between precision and recall.</li> <li>Formula: ( \\text{F1-Score} = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} )</li> </ul> </li> <li> <p>False Positive Rate (FPR):</p> <ul> <li>Measures the proportion of false positives among all actual negatives.</li> <li>Formula: ( \\text{FPR} = \\frac{\\text{False Positives}}{\\text{False Positives} + \\text{True Negatives}} )</li> </ul> </li> <li> <p>False Discovery Rate (FDR):</p> <ul> <li>Evaluates the proportion of false positive predictions among all positive predictions.</li> <li>Formula: ( \\text{FDR} = \\frac{\\text{False Positives}}{\\text{True Positives} + \\text{False Positives}} )</li> </ul> </li> <li> <p>Matthews Correlation Coefficient (MCC):</p> <ul> <li>Provides an overall measure of quality for binary classifications.</li> <li>Formula: ( \\text{MCC} = \\frac{(\\text{TP} \\cdot \\text{TN}) - (\\text{FP} \\cdot \\text{FN})}{\\sqrt{((\\text{TP} + \\text{FP})(\\text{TP} + \\text{FN})(\\text{TN} + \\text{FP})(\\text{TN} + \\text{FN}))}} )</li> </ul> </li> <li> <p>Area Under the Receiver Operating Characteristic Curve (AUC-ROC):</p> <ul> <li>Evaluates the performance of a binary classification model.</li> <li>The closer the AUC-ROC value is to 1, the better the model is at distinguishing between the positive and negative classes.</li> </ul> </li> <li> <p>Confusion Matrix:</p> <ul> <li>A table that is used to evaluate the performance of a classification model.</li> <li>Shows true positive, true negative, false positive, and false negative values which can be used to calculate other performance metrics.</li> </ul> </li> <li> <p>Mean Squared Error (MSE):</p> <ul> <li>Measures the average squared differences between the estimated values and the actual values.</li> <li>Formula: ( \\text{MSE} = \\frac{1}{n} \\sum (y_{\\text{true}} - y_{\\text{pred}})^2 )</li> </ul> </li> </ol>"},{"location":"release_notes/","title":"Release Notes","text":"<p>This page provides an overview of the changes made in each version of the Document Forensics project, including new features, improvements, and bug fixes.</p>"},{"location":"release_notes/#version-history","title":"Version History","text":""},{"location":"release_notes/#v120-2023-10-06","title":"[v1.2.0] - 2023-10-06","text":""},{"location":"release_notes/#new-features","title":"New Features:","text":"<ul> <li>Introduced API endpoints for forensic analysis.</li> <li>Added Gradio UI for easier interaction.</li> <li>Enhanced inpainting detection algorithms.</li> </ul>"},{"location":"release_notes/#improvements","title":"Improvements:","text":"<ul> <li>Improved performance and speed of the splicing detection.</li> <li>Optimized the project setup using Docker and Docker Compose.</li> </ul>"},{"location":"release_notes/#bug-fixes","title":"Bug Fixes:","text":"<ul> <li>Fixed an issue where the erasing detection was not accurate in certain cases.</li> <li>Addressed a bug that caused incorrect labeling in the Copy-Move detection.</li> </ul>"},{"location":"release_notes/#v110-2023-08-15","title":"[v1.1.0] - 2023-08-15","text":""},{"location":"release_notes/#new-features_1","title":"New Features:","text":"<ul> <li>Added support for more image formats including 'webp'.</li> <li>Introduced a new setup script for easier deployment.</li> </ul>"},{"location":"release_notes/#improvements_1","title":"Improvements:","text":"<ul> <li>Enhanced the accuracy of the Copy-Move detection.</li> <li>Improved the documentation for better understanding of the setup process.</li> </ul>"},{"location":"release_notes/#bug-fixes_1","title":"Bug Fixes:","text":"<ul> <li>Fixed a bug that caused the project to fail when processing large images.</li> <li>Addressed an issue where the Docker container would not start due to missing dependencies.</li> </ul>"},{"location":"release_notes/#v100-2023-02-17","title":"[v1.0.0] - 2023-02-17","text":""},{"location":"release_notes/#new-features_2","title":"New Features:","text":"<ul> <li>Initial release with basic forensic features including Copy-Move, Splicing, Erasing, Masking, and Inpainting detection.</li> <li>Provided Docker and Docker Compose setup for easy deployment.</li> </ul>"},{"location":"understanding_document_forensics_workflow/","title":"Understanding Document Forensics Workflow","text":""},{"location":"understanding_document_forensics_workflow/#how-the-solution-classifies-an-image","title":"How the Solution Classifies an Image:","text":"<p>The solution employs a trained model to identify the forgery regions within an image. These regions are illustrated in a mask, with white representing forged pixels and black denoting untouched pixels. The extent of white pixels serves as a basis to categorize an image as original, suspicious, or tampered.</p>"},{"location":"understanding_document_forensics_workflow/#steps","title":"Steps:","text":"<ol> <li> <p>Image Preparation:</p> <ul> <li>The image is loaded, resized to a resolution of 512x512 pixels, and all pixel values are normalized to a range of 0 to 1.</li> </ul> </li> <li> <p>Model Prediction:</p> <ul> <li>The trained deep learning model scrutinizes the image and generates a prediction mask in grayscale. This mask accentuates areas where tampering or forgery is presumed to have taken place.</li> </ul> </li> <li> <p>A \"mask\" in this context is an image of identical dimensions to the input, but instead of displaying the actual content, it unveils the regions (if any) identified as tampered.</p> </li> <li> <p>Mask Processing:</p> <ul> <li>To render decisions based on the mask, certain thresholds are applied to transition the grayscale mask to a monochromatic format (black and white). Pixel values below 128 are converted to 0 (indicating black), and pixel values above 128 are converted to 255 (indicating white).</li> </ul> </li> <li> <p>Forgery Extent Calculation:</p> <ul> <li>The proportion of the mask that is white (symbolic of forgery) is computed.</li> </ul> </li> <li> <p>Image Classification:</p> <ul> <li>Original: Classified if nearly no white pixels are present.</li> <li>Suspicious: The image might encompass some regions of forgery, but it's not definitive. If the white pixel percentage ranges between 0 to 0.57%, it will be labeled as suspicious.</li> <li>Tampered: Classified if the percentage of white pixels surpasses the upper threshold, i.e., if white pixels percentage is more than 0.57%.</li> </ul> </li> </ol> <p>Note: The thresholds for \"Suspicious\" and \"Tampered\" classifications can be adjusted as needed. These thresholds have been established based on the model's performance on Mauritius ID and Pancard images.</p>"},{"location":"understanding_document_forensics_workflow/#example-images-and-predicted-forgery-mask","title":"Example images and predicted forgery mask:","text":"# Image Predicted Mask Label 1 Original Image 2 Original Image 3 Tampered Image (Masking - text redaction) 4 Tampered Image (Copy-move) 5 Tampered Image (Splicing - face region changed)"},{"location":"user_guide/","title":"User Guide","text":"<p>This user guide provides detailed instructions on how to use the Document Forensic Project solution to analyze digital documents for potential tampering. The solution offers two interfaces for user access: Gradio UI and API interface.</p> <ul> <li>User Guide</li> <li>Access via Gradio UI</li> <li>Access via API Interface</li> </ul>"},{"location":"user_guide/#access-via-gradio-ui","title":"Access via Gradio UI","text":"<p>The Gradio UI provides a user-friendly interface to upload and analyze digital documents.</p> <p></p> <ol> <li> <p>Uploading Documents:</p> <ul> <li>Navigate to the Gradio UI.</li> <li>You can either drag and drop the document file onto the designated area or click to browse and select the file from your device.</li> </ul> </li> <li> <p>Submitting Documents for Analysis:</p> <ul> <li>Once the document file is selected, click on the <code>Submit</code> button to initiate the analysis.</li> </ul> </li> <li> <p>Viewing Analysis Results:</p> <ul> <li>Prediction Result: Label indicating the document's status as either <code>Original</code>, <code>Suspicious</code>, or <code>Tampered</code>.</li> <li>Stats: A key-value pair format displaying statistics of the predicted mask.</li> <li>Result Mask: A black and white monochrome mask generated from the grayscale predicted mask. White regions highlight the tampered or altered areas, while black regions signify untouched or genuine areas.</li> <li>Result Color Mask: An RGB color mask providing a colored representation of the analyzed areas.</li> <li>Document Integrity Verification Result: Key-value pairs indicating detected objects, along with their confidence levels.</li> </ul> </li> </ol>"},{"location":"user_guide/#access-via-api-interface","title":"Access via API Interface","text":"<p>The API interface provides a programmatic way to submit documents for analysis and retrieve the results.</p> <ol> <li> <p>API Endpoint:</p> <ul> <li>The API endpoint for document submission is <code>http://localhost:6003/analyze</code>.</li> </ul> </li> <li> <p>Submitting Documents for Analysis:</p> <ul> <li>Make a POST request to the API endpoint with the document file attached in the request body.</li> </ul> </li> <li> <p>Viewing Analysis Results:</p> <ul> <li>The analysis results will be returned in the response body, including Prediction Result, Stats, Result Mask, Result Color Mask, and Document Integrity Verification Result, similar to the Gradio UI.</li> </ul> </li> </ol> <p>For more information on the API parameters and response format, refer to the API documentation.</p>"}]}